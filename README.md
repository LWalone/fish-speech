# Fish Speech - Advanced Text-to-Speech with Speaker Management

[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_CN.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [æ—¥æœ¬èª](README_JP.md)

[![Docker Pulls](https://img.shields.io/docker/pulls/neosun/fish-speech)](https://hub.docker.com/r/neosun/fish-speech)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-1.2.0-green.svg)](https://github.com/neosun100/fish-speech/releases)

> ğŸŸ Advanced multilingual Text-to-Speech system with speaker management, auto-transcription, and emotion control

## âœ¨ Features

- ğŸ¤ **Speaker Management** - Register and reuse voice profiles
- ğŸ”„ **Auto-Transcription** - Automatic reference text generation with Whisper Turbo
- ğŸŒ **Multilingual** - Support for 8+ languages (EN, ZH, JA, KO, FR, DE, AR, ES)
- ğŸ˜Š **Emotion Control** - 40+ emotion and tone markers
- âš¡ **GPU Accelerated** - Fast inference with CUDA support
- ğŸ³ **Docker Ready** - One-command deployment
- ğŸ“¡ **REST API** - Complete FastAPI + Swagger documentation
- ğŸ¨ **WebUI** - User-friendly Gradio interface

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
docker run -d \
  --name fish-speech \
  --gpus all \
  -p 7864:7864 \
  -v $(pwd)/checkpoints:/app/checkpoints \
  -v $(pwd)/speakers:/app/speakers \
  neosun/fish-speech:all-in-one-v1.2.0
```

Access:
- WebUI: http://localhost:7864
- API Docs: http://localhost:7864/docs

### Option 2: From Source

```bash
# Clone repository
git clone https://github.com/neosun100/fish-speech.git
cd fish-speech

# Install dependencies
pip install -r requirements.txt

# Download models
# Place models in checkpoints/openaudio-s1-mini/

# Run server
python unified_server.py --port 7864 --device cuda
```

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10+
- CUDA 11.8+ (for GPU acceleration)
- Docker 20.10+ (for Docker deployment)
- 8GB+ GPU memory recommended

### Docker Deployment

#### Pull Image

```bash
docker pull neosun/fish-speech:all-in-one-v1.2.0
```

#### Run Container

```bash
docker run -d \
  --name fish-speech-v1.2.0 \
  --gpus '"device=0"' \
  -p 7864:7864 \
  -e PORT=7864 \
  -v $(pwd)/checkpoints:/app/checkpoints \
  -v $(pwd)/speakers:/app/speakers \
  --health-cmd "curl -f http://localhost:7864/health || exit 1" \
  --health-interval=30s \
  neosun/fish-speech:all-in-one-v1.2.0
```

#### Using Docker Compose

```yaml
version: '3.8'
services:
  fish-speech:
    image: neosun/fish-speech:all-in-one-v1.2.0
    container_name: fish-speech
    ports:
      - "7864:7864"
    environment:
      - PORT=7864
      - DEVICE=cuda
    volumes:
      - ./checkpoints:/app/checkpoints
      - ./speakers:/app/speakers
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7864/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

Run: `docker-compose up -d`

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | 7862 | Server port |
| `DEVICE` | cuda | Device (cuda/cpu) |
| `COMPILE` | 0 | Enable torch compile |
| `HALF` | 0 | Use half precision |
| `LLAMA_CHECKPOINT_PATH` | checkpoints/openaudio-s1-mini | Model path |

### Volume Mounts

- `/app/checkpoints` - Model files (required)
- `/app/speakers` - Speaker profiles (persistent storage)

## ğŸ’¡ Usage Examples

### 1. Register a Speaker

```bash
curl -X POST "http://localhost:7864/api/speakers" \
  -F "name=Alice" \
  -F "description=Professional female voice" \
  -F "audio=@reference.wav"
```

### 2. Generate Speech with Speaker

```bash
curl -X POST "http://localhost:7864/api/tts/speaker/{speaker_id}" \
  -F "text=Hello, this is a test." \
  -o output.wav
```

### 3. TTS with Emotions

```bash
curl -X POST "http://localhost:7864/api/tts" \
  -F "text=(excited) This is amazing! (laughing) Ha ha ha!" \
  -F "reference_audio=@voice.wav" \
  -o emotional_speech.wav
```

### 4. Auto-Transcription

```bash
curl -X POST "http://localhost:7864/api/transcribe" \
  -F "audio=@audio.wav"
```

## ğŸ“¡ API Documentation

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/api/gpu/status` | GPU status |
| POST | `/api/transcribe` | Transcribe audio |
| GET | `/api/speakers` | List speakers |
| POST | `/api/speakers` | Register speaker |
| GET | `/api/speakers/{id}` | Get speaker |
| PUT | `/api/speakers/{id}` | Update speaker |
| DELETE | `/api/speakers/{id}` | Delete speaker |
| POST | `/api/tts` | Generate speech |
| POST | `/api/tts/speaker/{id}` | TTS with speaker |

Full API documentation: http://localhost:7864/docs

## ğŸ—ï¸ Project Structure

```
fish-speech/
â”œâ”€â”€ unified_server.py      # Main server
â”œâ”€â”€ gpu_manager.py          # GPU management
â”œâ”€â”€ fish_speech/            # Core TTS engine
â”œâ”€â”€ tools/                  # Utilities
â”œâ”€â”€ checkpoints/            # Model files
â”œâ”€â”€ speakers/               # Speaker profiles
â”œâ”€â”€ Dockerfile.allinone     # Docker build
â””â”€â”€ docs/                   # Documentation
```

## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI + Gradio
- **Model**: OpenAudio S1-mini (0.5B parameters)
- **Transcription**: Whisper Turbo
- **Inference**: PyTorch + CUDA
- **Deployment**: Docker + NVIDIA Container Toolkit

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ Changelog

### v1.2.0 (2025-12-14)
- âœ¨ Added complete speaker management system
- âœ¨ Speaker registration with auto-transcription
- âœ¨ Persistent speaker storage
- ğŸ“š Complete API documentation

### v1.1.3 (2025-12-14)
- ğŸ› Fixed Gradio auto-transcription bug
- ğŸ”§ Improved audio file handling

### v1.1.2 (2025-12-14)
- âœ¨ Integrated Whisper Turbo
- âœ¨ Added transcription API

[Full Changelog](RELEASE_v1.2.0.md)

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

Model weights are released under CC-BY-NC-SA-4.0 License.

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/fish-speech&type=Date)](https://star-history.com/#neosun100/fish-speech)

## ğŸ“± Follow Us

![å…¬ä¼—å·](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)

---

**Made with â¤ï¸ by the Fish Speech Community**
